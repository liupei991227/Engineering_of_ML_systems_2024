# PIPELINE DEFINITION
# Name: bike-demand-pipeline
# Description: An example pipeline that deploys a model for bike demanding prediction
# Inputs:
#    hpo_trials: int
#    mae_threshold: float
#    mlflow_experiment_name: str
#    mlflow_s3_endpoint_url: str
#    mlflow_tracking_uri: str
#    model_name: str
#    random_seed: int
#    url: str
components:
  comp-condition-1:
    dag:
      tasks:
        deploy-model:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-deploy-model
          dependentTasks:
          - train
          inputs:
            parameters:
              model_name:
                componentInputParameter: pipelinechannel--model_name
              storage_uri:
                taskOutputParameter:
                  outputParameterKey: Output
                  producerTask: train
          taskInfo:
            name: deploy-model
        train:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-train
          inputs:
            artifacts:
              test_x_csv:
                componentInputArtifact: pipelinechannel--preprocess-data-test_x_csv
              test_y_csv:
                componentInputArtifact: pipelinechannel--preprocess-data-test_y_csv
              train_x_csv:
                componentInputArtifact: pipelinechannel--preprocess-data-train_x_csv
              train_y_csv:
                componentInputArtifact: pipelinechannel--preprocess-data-train_y_csv
            parameters:
              hyperparams:
                componentInputParameter: pipelinechannel--hpo-hyperparams
              mlflow_experiment_name:
                componentInputParameter: pipelinechannel--mlflow_experiment_name
              mlflow_s3_endpoint_url:
                componentInputParameter: pipelinechannel--mlflow_s3_endpoint_url
              mlflow_tracking_uri:
                componentInputParameter: pipelinechannel--mlflow_tracking_uri
              model_artifact_path:
                componentInputParameter: pipelinechannel--model_name
          taskInfo:
            name: train
    inputDefinitions:
      artifacts:
        pipelinechannel--preprocess-data-test_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        pipelinechannel--preprocess-data-test_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        pipelinechannel--preprocess-data-train_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        pipelinechannel--preprocess-data-train_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        pipelinechannel--hpo-best_mae:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--hpo-hyperparams:
          parameterType: STRUCT
        pipelinechannel--mae_threshold:
          parameterType: NUMBER_DOUBLE
        pipelinechannel--mlflow_experiment_name:
          parameterType: STRING
        pipelinechannel--mlflow_s3_endpoint_url:
          parameterType: STRING
        pipelinechannel--mlflow_tracking_uri:
          parameterType: STRING
        pipelinechannel--model_name:
          parameterType: STRING
  comp-deploy-model:
    executorLabel: exec-deploy-model
    inputDefinitions:
      parameters:
        model_name:
          parameterType: STRING
        storage_uri:
          parameterType: STRING
  comp-hpo:
    executorLabel: exec-hpo
    inputDefinitions:
      artifacts:
        test_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hpo_trials:
          defaultValue: 2.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        random_seed:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      parameters:
        best_mae:
          parameterType: NUMBER_DOUBLE
        hyperparams:
          parameterType: STRUCT
  comp-preprocess-data:
    executorLabel: exec-preprocess-data
    inputDefinitions:
      artifacts:
        data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        test_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-pull-data:
    executorLabel: exec-pull-data
    inputDefinitions:
      parameters:
        url:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-train:
    executorLabel: exec-train
    inputDefinitions:
      artifacts:
        test_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hyperparams:
          parameterType: STRUCT
        mlflow_experiment_name:
          parameterType: STRING
        mlflow_s3_endpoint_url:
          parameterType: STRING
        mlflow_tracking_uri:
          parameterType: STRING
        model_artifact_path:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-deploy-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - deploy_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'kserve==0.11.2'\
          \ 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport pandas as pd\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import\
          \ *\nfrom typing import *\n\ndef deploy_model(model_name: str, storage_uri:\
          \ str):\n    \"\"\"\n    Args:\n        model_name: the name of the deployed\
          \ inference service\n        storage_uri: the URI of the saved model in\
          \ MLflow's artifact store\n    \"\"\"\n    from kubernetes import client\n\
          \    from kserve import KServeClient\n    from kserve import constants\n\
          \    from kserve import V1beta1InferenceService\n    from kserve import\
          \ V1beta1InferenceServiceSpec\n    from kserve import V1beta1PredictorSpec\n\
          \    from kserve import V1beta1ModelSpec\n    from kserve import V1beta1ModelFormat\n\
          \    import logging\n\n    logging.basicConfig(level=logging.INFO)\n   \
          \ logger = logging.getLogger(__name__)\n\n    namespace = \"kserve-inference\"\
          \n    service_account_name = \"kserve-sa\"\n    api_version = constants.KSERVE_V1BETA1\n\
          \    logger.info(f\"MODEL URI: {storage_uri}\")\n\n    modelspec = V1beta1ModelSpec(\n\
          \        storage_uri=storage_uri,\n        model_format=V1beta1ModelFormat(name=\"\
          mlflow\"),\n        protocol_version=\"v2\"\n    )\n\n    ### START CODE\
          \ HERE\n    # Define the inference service specification\n    isvc = V1beta1InferenceService(\n\
          \        api_version=api_version,\n        kind=constants.KSERVE_KIND,\n\
          \        metadata=client.V1ObjectMeta(\n            name=model_name,\n \
          \           namespace=namespace\n        ),\n        spec=V1beta1InferenceServiceSpec(\n\
          \            predictor=V1beta1PredictorSpec(\n                model=modelspec,\n\
          \                service_account_name=service_account_name\n           \
          \ )\n        )\n    )\n\n    # Create the KServe client\n    kserve_client\
          \ = KServeClient(config_file=\"/root/.kube/config\")\n\n    try:\n     \
          \   # Delete the existing inference service if it exists\n        try:\n\
          \            kserve_client.delete(model_name, namespace=namespace)\n   \
          \         logger.info(f\"Deleted existing inference service '{model_name}'.\"\
          )\n            time.sleep(100)\n        except Exception as delete_err:\n\
          \            logger.warning(f\"Failed to delete existing inference service:\
          \ {delete_err}\")\n\n        # Create a new inference service\n        kserve_client.create(isvc)\n\
          \        logger.info(f\"Inference service '{model_name}' creation initiated.\"\
          )\n\n        # Wait for the inference service to become ready\n        kserve_client.wait_isvc_ready(model_name,\
          \ namespace=namespace)\n        logger.info(f\"Inference service '{model_name}'\
          \ is ready.\")\n\n    except Exception as e:\n        logger.error(f\"Failed\
          \ to create inference service: {e}\")\n        raise\n    ### END CODE HERE\n\
          \n"
        image: python:3.11
    exec-hpo:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - hpo
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'pandas~=2.2.0'\
          \ 'numpy~=1.26.4' 'lightgbm==3.3.5' 'optuna==3.5.0' 'scikit-learn~=1.4.0'\
          \ 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error,\
          \ r2_score\nimport optuna\nimport lightgbm as lgb\nimport pandas as pd\n\
          import kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef hpo(\n    train_x_csv: Input[Dataset],\n    train_y_csv: Input[Dataset],\n\
          \    test_x_csv: Input[Dataset],\n    test_y_csv: Input[Dataset],\n    hpo_trials:\
          \ int = 2,\n    random_seed: int = 42\n) -> NamedTuple(\n    \"Output\"\
          ,\n    [\n        (\"hyperparams\", Dict[str, Any]),\n        (\"best_mae\"\
          , float),\n    ],\n):\n    \"\"\"\n    Args:\n        train_x_csv: Input\
          \ where the training feature data is saved\n        train_y_csv: Input where\
          \ the training target data is saved\n        test_x_csv: Input where the\
          \ test feature data is saved\n        test_y_csv: Input where the test target\
          \ data is saved\n        hpo_trials: The number of trials that the Optuna\
          \ study should run\n        random_seed: The random seed used for model\
          \ training and t TPESampler\n    Returns:\n        namedtuple(\"Output\"\
          , [\"hyperparams\", \"best_mae\"]) where hyperparams is the best hyperparameter\
          \ combination found by the optimization \n        and best_mae is the best\
          \ MAE found by the optimization. The hyperparams is a dictionary where the\
          \ keys are the hyperparameter names \n        and values the hyperparameter\
          \ values. It should also contain the random_state used in model training.\
          \ \n        The returned namedtuple should be like:\n        Output(hyperparams={'learning_rate':\
          \ ..., 'colsample_bytree': ..., 'num_leaves': ..., 'random_state': <random_seed>},\
          \ best_mae=...)  \n    \"\"\"\n    # TODO:\n    # 1. Read the feature and\
          \ target datasets \n    # 2. Define the objective function\n    # 3. Create\
          \ an Optuna study and run it. Assign the study to the \"study\" variable,\
          \ i.e., study=optuna.create_study(...)\n    ### START CODE HERE\n    # Load\
          \ the datasets\n    train_x = pd.read_csv(train_x_csv.path)\n    train_y\
          \ = pd.read_csv(train_y_csv.path).squeeze()  # Convert to a Series\n   \
          \ test_x = pd.read_csv(test_x_csv.path)\n    test_y = pd.read_csv(test_y_csv.path).squeeze()\
          \    # Convert to a Series\n\n    # Define the Optuna objective function\n\
          \    def objective(trial):\n        params = {\n            \"learning_rate\"\
          : trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n      \
          \      \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5,\
          \ 1),\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2,\
          \ 1024),\n            \"random_state\": random_seed,\n\n        }\n\n  \
          \      # Train LightGBM model\n        model = lgb.LGBMRegressor(**params)\n\
          \        model.fit(train_x, train_y, eval_set=[(test_x, test_y)], eval_metric=\"\
          mae\", early_stopping_rounds=10, verbose=False)\n\n        # Predict and\
          \ calculate MAE\n        predictions = model.predict(test_x)\n        mae\
          \ = mean_absolute_error(test_y, predictions)\n        return mae\n\n   \
          \ # Create the Optuna study\n    study = optuna.create_study(\n        direction=\"\
          minimize\",\n        sampler=optuna.samplers.TPESampler(seed=random_seed)\n\
          \    )\n\n    # Optimize the study\n    study.optimize(objective, n_trials=hpo_trials)\n\
          \    ### END CODE HERE\n\n    # Insert the random_state into the hyperparams\
          \ when prepare the output namedtuple\n    hyperparams = {key: value for\
          \ key, value in study.best_params.items()}\n    hyperparams[\"random_state\"\
          ] = random_seed\n\n    # TODO: Construct and return the namedtuple\n\n \
          \   ### START CODE HERE\n    # Return the results\n    best_mae = study.best_value\n\
          \    Output = NamedTuple(\n        \"Output\",\n        [(\"hyperparams\"\
          , Dict[str, Any]), (\"best_mae\", float)],\n    )\n    return Output(hyperparams,\
          \ best_mae)\n\n    ### END CODE HERE\n\n"
        image: python:3.11
    exec-preprocess-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'pandas~=2.2.0'\
          \ 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport pandas as pd\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import\
          \ *\nfrom typing import *\n\ndef preprocess_data(\n    data: Input[Dataset],\n\
          \    train_x_csv: Output[Dataset],\n    train_y_csv: Output[Dataset],\n\
          \    test_x_csv: Output[Dataset],\n    test_y_csv: Output[Dataset],\n):\n\
          \    \"\"\"\n    Args:\n        data: Input of type Dataset where the dataset\
          \ is read from\n        train_x_csv: Output of type Dataset where the training\
          \ features are saved\n        train_y_csv: Output of type Dataset where\
          \ the training target is saved\n        test_x_csv: Output of type Dataset\
          \ where the test features are saved\n        test_y_csv: Output of type\
          \ Dataset where the test target is saved\n    \"\"\"\n    target = \"count\"\
          \n\n    ### START CODE HERE\n    # Read the dataset\n    df = pd.read_csv(data.path)\n\
          \n    # Convert \"datetime\" to Pandas datetime object\n    df[\"datetime\"\
          ] = pd.to_datetime(df[\"datetime\"])\n\n    # Create new features from the\
          \ \"datetime\" column\n    df[\"hour\"] = df[\"datetime\"].dt.hour\n   \
          \ df[\"day\"] = df[\"datetime\"].dt.day\n    df[\"month\"] = df[\"datetime\"\
          ].dt.month\n\n    # Drop unnecessary columns\n    df = df.drop(columns=[\"\
          datetime\", \"casual\", \"registered\"])\n\n    # Split into training and\
          \ test datasets\n    train_df = df.iloc[:-168]\n    test_df = df.iloc[-168:]\n\
          \n    # Split features and target\n    train_x = train_df.drop(columns=[target])\n\
          \    train_y = train_df[[target]]\n    test_x = test_df.drop(columns=[target])\n\
          \    test_y = test_df[[target]]\n\n    # Save datasets to output paths\n\
          \    train_x.to_csv(train_x_csv.path, index=False)\n    train_y.to_csv(train_y_csv.path,\
          \ index=False)\n    test_x.to_csv(test_x_csv.path, index=False)\n    test_y.to_csv(test_y_csv.path,\
          \ index=False)\n    ### END CODE HERE\n\n"
        image: python:3.11
    exec-pull-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - pull_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'pandas~=2.2.0'\
          \ 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport pandas as pd\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import\
          \ *\nfrom typing import *\n\ndef pull_data(url: str, data: Output[Dataset]):\n\
          \    \"\"\"\n    Args:\n        url: Dataset URL\n        data: Output of\
          \ type Dataset where the downloaded dataset is saved\n    \"\"\"\n    ###\
          \ START CODE HERE\n    df = pd.read_csv(url)\n    df.to_csv(data.path, index=False)\n\
          \    ### END CODE HERE\n\n"
        image: python:3.11
    exec-train:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'pandas~=2.2.0'\
          \ 'numpy~=1.26.4' 'lightgbm~=3.3.5' 'scikit-learn~=1.4.0' 'mlflow==2.9.2'\
          \ 'boto3~=1.34.40' 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error,\
          \ mean_squared_error, r2_score\nimport boto3\nimport mlflow\nimport os\n\
          import pandas as pd\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import\
          \ *\nfrom typing import *\n\ndef train(\n    train_x_csv: Input[Dataset],\n\
          \    train_y_csv: Input[Dataset],\n    test_x_csv: Input[Dataset],\n   \
          \ test_y_csv: Input[Dataset],\n    mlflow_experiment_name: str,\n    mlflow_tracking_uri:\
          \ str,\n    mlflow_s3_endpoint_url: str,\n    model_artifact_path: str,\n\
          \    hyperparams: Dict[str, Any],\n) -> str: \n    \"\"\"\n    Args:\n \
          \       train_x_csv: Input where the training feature data is saved\n  \
          \      train_y_csv: Input where the training target data is saved\n    \
          \    test_x_csv: Input where the test feature data is saved\n        test_y_csv:\
          \ Input where the test target data is saved\n        mlflow_experiment_name:\
          \ Name of the MLflow experiment\n        mlflow_tracking_uri: URI of MLflow's\
          \ tracking server\n        mlflow_s3_endpoint_url: URL of MLflow's artifact\
          \ store\n        model_artifact_path: The path where the artifacts of the\
          \ model are stored in MLflow's artifact store. It's relative to the MLflow\
          \ Run.\n        hyperparams: Hyperparameters that need to be configured.\
          \ The hyperparameters will be passed as a dictionary like {\"num_leaves\"\
          : 1023, \"learning_rate\": 0.05}\n\n    Returns: \n        The S3 URI of\
          \ the saved model in Mlflow's artifact store, e.g., s3://mlflow/13/e5559bc.../artifacts/bike-demand\n\
          \    \"\"\"\n    ### START CODE HERE\n    # Load the datasets\n    train_x\
          \ = pd.read_csv(train_x_csv.path)\n    train_y = pd.read_csv(train_y_csv.path).squeeze()\
          \  # Convert to a Series\n    test_x = pd.read_csv(test_x_csv.path)\n  \
          \  test_y = pd.read_csv(test_y_csv.path).squeeze()    # Convert to a Series\n\
          \n    # Set MLflow tracking URI and experiment name\n    mlflow.set_tracking_uri(mlflow_tracking_uri)\n\
          \    mlflow.set_experiment(mlflow_experiment_name)\n\n    # Start an MLflow\
          \ run\n    with mlflow.start_run():\n        os.environ[\"AWS_ACCESS_KEY_ID\"\
          ] = \"minioadmin\"\n        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\
          \n        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = mlflow_s3_endpoint_url\n\
          \        # Create and train the LightGBM model\n        model = lgb.LGBMRegressor(**hyperparams)\n\
          \        model.fit(train_x, train_y)\n\n        # Make predictions on the\
          \ test set\n        test_pred = model.predict(test_x)\n\n        # Calculate\
          \ evaluation metrics\n        rmse = mean_squared_error(test_y, test_pred,\
          \ squared=False)  # RMSE\n        mae = mean_absolute_error(test_y, test_pred)\
          \  # MAE\n        r2 = r2_score(test_y, test_pred)  # R\xB2\n\n        #\
          \ Log hyperparameters\n        for param, value in hyperparams.items():\n\
          \            mlflow.log_param(param, value)\n\n        # Log metrics\n \
          \       mlflow.log_metric(\"rmse\", rmse)\n        mlflow.log_metric(\"\
          mae\", mae)\n        mlflow.log_metric(\"r2\", r2)\n\n        # Log the\
          \ model to MLflow\n        mlflow.lightgbm.log_model(model, artifact_path=model_artifact_path,\
          \ registered_model_name=mlflow_experiment_name)\n\n\n        # Get the S3\
          \ URI of the saved model\n        model_uri = mlflow.get_artifact_uri(artifact_path=model_artifact_path)\n\
          \n        # Return the S3 URI of the saved model\n        return model_uri\n\
          \    ### END CODE HERE\n\n"
        image: python:3.11
pipelineInfo:
  description: An example pipeline that deploys a model for bike demanding prediction
  name: bike-demand-pipeline
root:
  dag:
    tasks:
      condition-1:
        componentRef:
          name: comp-condition-1
        dependentTasks:
        - hpo
        - preprocess-data
        inputs:
          artifacts:
            pipelinechannel--preprocess-data-test_x_csv:
              taskOutputArtifact:
                outputArtifactKey: test_x_csv
                producerTask: preprocess-data
            pipelinechannel--preprocess-data-test_y_csv:
              taskOutputArtifact:
                outputArtifactKey: test_y_csv
                producerTask: preprocess-data
            pipelinechannel--preprocess-data-train_x_csv:
              taskOutputArtifact:
                outputArtifactKey: train_x_csv
                producerTask: preprocess-data
            pipelinechannel--preprocess-data-train_y_csv:
              taskOutputArtifact:
                outputArtifactKey: train_y_csv
                producerTask: preprocess-data
          parameters:
            pipelinechannel--hpo-best_mae:
              taskOutputParameter:
                outputParameterKey: best_mae
                producerTask: hpo
            pipelinechannel--hpo-hyperparams:
              taskOutputParameter:
                outputParameterKey: hyperparams
                producerTask: hpo
            pipelinechannel--mae_threshold:
              componentInputParameter: mae_threshold
            pipelinechannel--mlflow_experiment_name:
              componentInputParameter: mlflow_experiment_name
            pipelinechannel--mlflow_s3_endpoint_url:
              componentInputParameter: mlflow_s3_endpoint_url
            pipelinechannel--mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            pipelinechannel--model_name:
              componentInputParameter: model_name
        taskInfo:
          name: condition-1
        triggerPolicy:
          condition: inputs.parameter_values['pipelinechannel--hpo-best_mae'] < inputs.parameter_values['pipelinechannel--mae_threshold']
      hpo:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-hpo
        dependentTasks:
        - preprocess-data
        inputs:
          artifacts:
            test_x_csv:
              taskOutputArtifact:
                outputArtifactKey: test_x_csv
                producerTask: preprocess-data
            test_y_csv:
              taskOutputArtifact:
                outputArtifactKey: test_y_csv
                producerTask: preprocess-data
            train_x_csv:
              taskOutputArtifact:
                outputArtifactKey: train_x_csv
                producerTask: preprocess-data
            train_y_csv:
              taskOutputArtifact:
                outputArtifactKey: train_y_csv
                producerTask: preprocess-data
          parameters:
            hpo_trials:
              componentInputParameter: hpo_trials
            random_seed:
              componentInputParameter: random_seed
        taskInfo:
          name: hpo
      preprocess-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess-data
        dependentTasks:
        - pull-data
        inputs:
          artifacts:
            data:
              taskOutputArtifact:
                outputArtifactKey: data
                producerTask: pull-data
        taskInfo:
          name: preprocess-data
      pull-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-pull-data
        inputs:
          parameters:
            url:
              componentInputParameter: url
        taskInfo:
          name: pull-data
  inputDefinitions:
    parameters:
      hpo_trials:
        parameterType: NUMBER_INTEGER
      mae_threshold:
        parameterType: NUMBER_DOUBLE
      mlflow_experiment_name:
        parameterType: STRING
      mlflow_s3_endpoint_url:
        parameterType: STRING
      mlflow_tracking_uri:
        parameterType: STRING
      model_name:
        parameterType: STRING
      random_seed:
        parameterType: NUMBER_INTEGER
      url:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.0.1
