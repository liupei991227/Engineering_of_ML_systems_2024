# PIPELINE DEFINITION
# Name: train
# Inputs:
#    hyperparams: dict
#    mlflow_experiment_name: str
#    mlflow_s3_endpoint_url: str
#    mlflow_tracking_uri: str
#    model_artifact_path: str
#    test_x_csv: system.Dataset
#    test_y_csv: system.Dataset
#    train_x_csv: system.Dataset
#    train_y_csv: system.Dataset
# Outputs:
#    Output: str
components:
  comp-train:
    executorLabel: exec-train
    inputDefinitions:
      artifacts:
        test_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Input where the test feature data is saved
        test_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Input where the test target data is saved
        train_x_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Input where the training feature data is saved
        train_y_csv:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Input where the training target data is saved
      parameters:
        hyperparams:
          description: 'Hyperparameters that need to be configured. The hyperparameters
            will be passed as a dictionary like {"num_leaves": 1023, "learning_rate":
            0.05}'
          parameterType: STRUCT
        mlflow_experiment_name:
          description: Name of the MLflow experiment
          parameterType: STRING
        mlflow_s3_endpoint_url:
          description: URL of MLflow's artifact store
          parameterType: STRING
        mlflow_tracking_uri:
          description: URI of MLflow's tracking server
          parameterType: STRING
        model_artifact_path:
          description: The path where the artifacts of the model are stored in MLflow's
            artifact store. It's relative to the MLflow Run.
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-train:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'pandas~=2.2.0'\
          \ 'numpy~=1.26.4' 'lightgbm~=3.3.5' 'scikit-learn~=1.4.0' 'mlflow==2.9.2'\
          \ 'boto3~=1.34.40' 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport boto3\nimport mlflow\nimport os\nimport pandas as pd\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train(\n    train_x_csv: Input[Dataset],\n    train_y_csv: Input[Dataset],\n\
          \    test_x_csv: Input[Dataset],\n    test_y_csv: Input[Dataset],\n    mlflow_experiment_name:\
          \ str,\n    mlflow_tracking_uri: str,\n    mlflow_s3_endpoint_url: str,\n\
          \    model_artifact_path: str,\n    hyperparams: Dict[str, Any],\n) -> str:\
          \ \n    \"\"\"\n    Args:\n        train_x_csv: Input where the training\
          \ feature data is saved\n        train_y_csv: Input where the training target\
          \ data is saved\n        test_x_csv: Input where the test feature data is\
          \ saved\n        test_y_csv: Input where the test target data is saved\n\
          \        mlflow_experiment_name: Name of the MLflow experiment\n       \
          \ mlflow_tracking_uri: URI of MLflow's tracking server\n        mlflow_s3_endpoint_url:\
          \ URL of MLflow's artifact store\n        model_artifact_path: The path\
          \ where the artifacts of the model are stored in MLflow's artifact store.\
          \ It's relative to the MLflow Run.\n        hyperparams: Hyperparameters\
          \ that need to be configured. The hyperparameters will be passed as a dictionary\
          \ like {\"num_leaves\": 1023, \"learning_rate\": 0.05}\n\n    Returns: \n\
          \        The S3 URI of the saved model in Mlflow's artifact store, e.g.,\
          \ s3://mlflow/13/e5559bc.../artifacts/bike-demand\n    \"\"\"\n    ### START\
          \ CODE HERE\n    # Load the datasets\n    train_x = pd.read_csv(train_x_csv.path)\n\
          \    train_y = pd.read_csv(train_y_csv.path).squeeze()  # Convert to a Series\n\
          \    test_x = pd.read_csv(test_x_csv.path)\n    test_y = pd.read_csv(test_y_csv.path).squeeze()\
          \    # Convert to a Series\n\n    # Set MLflow tracking URI and experiment\
          \ name\n    mlflow.set_tracking_uri(mlflow_tracking_uri)\n    mlflow.set_experiment(mlflow_experiment_name)\n\
          \n    # Start an MLflow run\n    with mlflow.start_run():\n        os.environ[\"\
          AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n        os.environ[\"AWS_SECRET_ACCESS_KEY\"\
          ] = \"minioadmin\"\n        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = mlflow_s3_endpoint_url\
          \n        # Create and train the LightGBM model\n\
          \        model = lgb.LGBMRegressor(**hyperparams)\n        model.fit(train_x,\
          \ train_y)\n\n        # Make predictions on the test set\n        test_pred\
          \ = model.predict(test_x)\n\n        # Calculate evaluation metrics\n  \
          \      rmse = mean_squared_error(test_y, test_pred, squared=False)  # RMSE\n\
          \        mae = mean_absolute_error(test_y, test_pred)  # MAE\n        r2\
          \ = r2_score(test_y, test_pred)  # R\xB2\n\n        # Log hyperparameters\n\
          \        for param, value in hyperparams.items():\n            mlflow.log_param(param,\
          \ value)\n\n        # Log metrics\n        mlflow.log_metric(\"rmse\", rmse)\n\
          \        mlflow.log_metric(\"mae\", mae)\n        mlflow.log_metric(\"r2\"\
          , r2)\n\n        # Log the model to MLflow\n        mlflow.lightgbm.log_model(model,\
          \ artifact_path=model_artifact_path, registered_model_name=mlflow_experiment_name)\n\
          \n\n        # Get the S3 URI of the saved model\n        model_uri = mlflow.get_artifact_uri(artifact_path=model_artifact_path)\n\
          \n        # Return the S3 URI of the saved model\n        return model_uri\n\
          \    ### END CODE HERE\n\n"
        image: python:3.11
pipelineInfo:
  name: train
root:
  dag:
    outputs:
      parameters:
        Output:
          valueFromParameter:
            outputParameterKey: Output
            producerSubtask: train
    tasks:
      train:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train
        inputs:
          artifacts:
            test_x_csv:
              componentInputArtifact: test_x_csv
            test_y_csv:
              componentInputArtifact: test_y_csv
            train_x_csv:
              componentInputArtifact: train_x_csv
            train_y_csv:
              componentInputArtifact: train_y_csv
          parameters:
            hyperparams:
              componentInputParameter: hyperparams
            mlflow_experiment_name:
              componentInputParameter: mlflow_experiment_name
            mlflow_s3_endpoint_url:
              componentInputParameter: mlflow_s3_endpoint_url
            mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            model_artifact_path:
              componentInputParameter: model_artifact_path
        taskInfo:
          name: train
  inputDefinitions:
    artifacts:
      test_x_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
        description: Input where the test feature data is saved
      test_y_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
        description: Input where the test target data is saved
      train_x_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
        description: Input where the training feature data is saved
      train_y_csv:
        artifactType:
          schemaTitle: system.Dataset
          schemaVersion: 0.0.1
        description: Input where the training target data is saved
    parameters:
      hyperparams:
        description: 'Hyperparameters that need to be configured. The hyperparameters
          will be passed as a dictionary like {"num_leaves": 1023, "learning_rate":
          0.05}'
        parameterType: STRUCT
      mlflow_experiment_name:
        description: Name of the MLflow experiment
        parameterType: STRING
      mlflow_s3_endpoint_url:
        description: URL of MLflow's artifact store
        parameterType: STRING
      mlflow_tracking_uri:
        description: URI of MLflow's tracking server
        parameterType: STRING
      model_artifact_path:
        description: The path where the artifacts of the model are stored in MLflow's
          artifact store. It's relative to the MLflow Run.
        parameterType: STRING
  outputDefinitions:
    parameters:
      Output:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.0.1
